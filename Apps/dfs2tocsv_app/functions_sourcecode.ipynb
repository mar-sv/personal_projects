{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mikeio as mi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gdp\n",
    "from shapely.geometry import Point, LineString\n",
    "import sys\n",
    "from math import atan2, degrees, hypot,radians,cos,sin\n",
    "import shapely.wkt\n",
    "import shapely.ops\n",
    "\n",
    "\n",
    "def reverse_geom(geom):\n",
    "    def _reverse(x, y, z=None):\n",
    "        if z:\n",
    "            return x[::-1], y[::-1], z[::-1]\n",
    "        return x[::-1], y[::-1]\n",
    "\n",
    "    return shapely.ops.transform(_reverse, geom)\n",
    "\n",
    "\n",
    "def get_grid_size(ds):\n",
    "    # Check if quadratic grid\n",
    "    if ds.geometry.dx != ds.geometry.dy:\n",
    "        print('The grid is not quadratic. This might cause insufficient results')\n",
    "    return ds.geometry.dx\n",
    "\n",
    "\n",
    "def PerpendicularFor2Points(pointA, pointB):\n",
    "    changeInX = pointB[0] - pointA[0]\n",
    "    changeInY = pointB[1] - pointA[1]\n",
    "    return atan2(changeInY, changeInX)\n",
    "\n",
    "def calculate_flow_magnitude(df, grid_size, perpendicular_line):\n",
    "    # Get the columns of the df. The two columns that will be used for further calculations are the P flux (flow in x direction, index = 2) and Q Flux (flow in y direction, index = 3).\n",
    "    columns = df.columns\n",
    "\n",
    "    # Get the coordinates of the subline and calculate its angle. Get the perpendicular line. \n",
    "    coord_list = list(sub_line.coords)\n",
    "    start_coord = coord_list[0]\n",
    "    end_coord = coord_list[1]\n",
    "    angle_line = PerpendicularFor2Points(start_coord, end_coord)\n",
    "    perpendicular_line = angle_line + radians(90)\n",
    "\n",
    "\n",
    "\n",
    "    # Resultant flow is given by hypothenuse of both. Note that the flow is given in per meter, meaning that we need to multiply by the grid size\n",
    "    df['Discharge [meter^3/s]'] = df.apply(\n",
    "        lambda x: x[columns[3]]*sin(perpendicular_line) +  x[columns[2]]*cos(perpendicular_line), axis=1)\n",
    "    # df['Discharge'] = df['Discharge']\n",
    "    df['flow_direction'] = df.apply(lambda x: degrees(\n",
    "        atan2(x[columns[3]], x[columns[2]])), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    # Update the columns, and calculate flow direction\n",
    "    columns = df.columns\n",
    "    df['Discharge [meter^3/s]'] = df.apply(lambda x: x[columns[4]] if calculate_flow_direction(\n",
    "        perpendicular_line, x[columns[5]]) else x[columns[4]]*-1, axis=1)\n",
    "    df['Discharge + [meter^3/s]'] = df.apply(\n",
    "        lambda x: x[columns[4]] if x[columns[4]] > 0 else 0, axis=1)\n",
    "    df['Discharge - [meter^3/s]'] = df.apply(\n",
    "        lambda x: x[columns[4]] if x[columns[4]] < 0 else 0, axis=1)\n",
    "\n",
    "    # Calculate the cumulative sum of the flows\n",
    "    df['Cum. disc. + [meter^3]'] = np.cumsum(df['Discharge + [meter^3/s]'])\n",
    "    df['Cum. disc. - [meter^3]'] = np.cumsum(df['Discharge - [meter^3/s]'])\n",
    "    df['Cum. disc. [meter^3/s]'] = np.cumsum(df['Discharge [meter^3/s]'])\n",
    "    return df[['time','Discharge + [meter^3/s]', 'Discharge - [meter^3/s]', 'Discharge [meter^3/s]', 'Cum. disc. + [meter^3]', 'Cum. disc. - [meter^3]', 'Cum. disc. [meter^3/s]']]\n",
    "\n",
    "\n",
    "def get_values_for_linestring(grid_size, ds, geometry_row):\n",
    "\n",
    "    # Number of points in the polyline\n",
    "    num_coords = len(geometry_row.coords)\n",
    "\n",
    "    # Convert gridsize to integer\n",
    "    grid_size = int(grid_size)\n",
    "\n",
    "    # We will take timesteps equal to grid_size/2 in order not to miss any of the cells.\n",
    "    # However, in order to not duplicate any of the cells, we need to check whether the coordinates have been calculated before\n",
    "    calculated_coords = []\n",
    "\n",
    "    # Loop through each coordinate, create a new polyline for each and extract result\n",
    "    for j in range(1, num_coords):\n",
    "\n",
    "        # Define start and end coordinates\n",
    "        starting_coord = geometry_row.coords[j-1]\n",
    "        end_coord = geometry_row.coords[j]\n",
    "        # Create new LineString of new coordinates and calculate its perpendicular angle\n",
    "        sub_line = LineString([starting_coord, end_coord])\n",
    "        perpendicular_angle = PerpendicularFor2Points(starting_coord,end_coord)\n",
    "\n",
    "        # Round the length of the line to closest integer and convert\n",
    "        length_of_line = int(\n",
    "            np.round(Point(starting_coord).distance(Point(end_coord)), 0))\n",
    "\n",
    "        # Loop thorugh the values in the dfs2 file, with the step size equivalent to the gridsize\n",
    "        for i in range(1, length_of_line, grid_size):\n",
    "            \n",
    "            if i == 1:\n",
    "                point_array = ds.sel(x=ip.coords[0][0], y=ip.coords[0][1])\n",
    "                calculated_coords.append([point_array.geometry.x,point_array.geometry.y])\n",
    "                prev_df = point_array.to_dataframe()\n",
    "                \n",
    "            # Get coordinates of point with i distance from start coordinate\n",
    "            ip = sub_line.interpolate(distance=i)\n",
    "            point_array = ds.sel(x=ip.coords[0][0], y=ip.coords[0][1])\n",
    "\n",
    "            #REMEMBER! NOW THE IDEA IS TO TAKE THE PREV_DF AND CURR_DF AND CALCULATE THE AVERAGE!!!!!\n",
    "            # Check whether the point have been calculated before\n",
    "            new_coord_list = [point_array.geometry.x, point_array.geometry.y]\n",
    "            if new_coord_list not in calculated_coords:\n",
    "                # Create a df with this cross sections values\n",
    "                df_next_coord = point_array.to_dataframe()\n",
    "\n",
    "                # Calculate flow magnitude and its direction\n",
    "                df_next_coord = calculate_flow_magnitude(\n",
    "                    df_next_coord, grid_size, sub_line)\n",
    "                # Concatenate the results of the new coordinate to result_df. Note that here they are concatenated vertically\n",
    "                df_result = pd.concat([df_result, df_next_coord])\n",
    "\n",
    "                # append the coordinates to calculated_coords\n",
    "                calculated_coords.append(new_coord_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # TEST! Include last coord.\n",
    "    # Extract results\n",
    "    point_array = ds.sel(x=end_coord[0], y=end_coord[1])\n",
    "    new_coord_list = [point_array.geometry.x, point_array.geometry.y]\n",
    "\n",
    "    if new_coord_list not in calculated_coords:\n",
    "        # Extract results for each item in the dfs2\n",
    "        # print(\"Du missade sista!!!\")\n",
    "        df_next = point_array.to_dataframe()\n",
    "        df_next_coord = calculate_flow_magnitude(\n",
    "            df_next, grid_size, sub_line)\n",
    "        # Add the coordinates of point_array to our memory list\n",
    "        df_result = pd.concat([df_result, df_next_coord])\n",
    "        calculated_coords.append(new_coord_list)\n",
    "\n",
    "    df_result = df_result.groupby('time', as_index=False).sum()\n",
    "    # For swedish users, the , is the default separator, instead of . (This is a feature requested by the user)\n",
    "    # columns = df_result.columns\n",
    "    # for col in columns:\n",
    "    #    df_result[col] = df_result[col].astype(\n",
    "    #        str).str.replace('.', ',', regex=False)\n",
    "\n",
    "    return df_result,calculated_coords,point_array\n",
    "\n",
    "\n",
    "def dfs2tocsv(filepath_ds, filepath_shape,output_dir_and_name):\n",
    "\n",
    "    # Check whether it is a dfs2 file or not\n",
    "    if filepath_ds[-4:] != 'dfs2':\n",
    "        print(\"Please pick a dfs2 file\")\n",
    "        return False\n",
    "\n",
    "    # Read dfs2\n",
    "    ds = mi.read(filepath_ds)\n",
    "\n",
    "    # Check whether it is a shp file or not\n",
    "    if filepath_shape[-3:] != 'shp':\n",
    "        print(\"Please pick a shapefile\")\n",
    "        return False\n",
    "\n",
    "    # Read shapefile\n",
    "    shape_df = gdp.read_file(filepath_shape)\n",
    "\n",
    "    # Check whether the file is a Polyline\n",
    "    if not isinstance(shape_df['geometry'][0], LineString):\n",
    "        print('The file is not a Polyline, please specify a Polyline instead.')\n",
    "        return False\n",
    "    \n",
    "    index_check = 0\n",
    "    #Check whether the ids are unique in the shapefile\n",
    "    if len(shape_df['Id']) != shape_df['Id'].nunique():\n",
    "        index_check = 1\n",
    "        print('The values in the Id column in the shapefile is not unique. The sheets will be named after polyline index')\n",
    "\n",
    "    # Get grid size\n",
    "    grid_size = get_grid_size(ds)\n",
    "\n",
    "    # Dictionary with results\n",
    "    df_dict = {}\n",
    "\n",
    "    # Loop through df with the shapefile and save the results\n",
    "    for index, row in shape_df.iterrows():\n",
    "\n",
    "        # Check direction. The calculations should always be done from left to right.\n",
    "        first_coord = row['geometry'].coords[0]\n",
    "        last_coord = row['geometry'].coords[len(row['geometry'].coords)-1]\n",
    "        angle = AngleBtw2Points(first_coord, last_coord)\n",
    "\n",
    "        # If angle is in the second or third quadrant, the general direction is right, so it must be reversed\n",
    "        if (angle > 90) | (angle < -90):\n",
    "            row['geometry'] = reverse_geom(row['geometry'])\n",
    "            #print(\n",
    "            #    'The cross section is defined from right to left. The cross section will be reversed.')\n",
    "        if index_check == 1:\n",
    "            df_dict[index] = get_values_for_linestring(\n",
    "                grid_size, ds, row['geometry'])\n",
    "        else:\n",
    "            df_dict[row['Id']] = get_values_for_linestring(\n",
    "                grid_size, ds, row['geometry'])\n",
    "        \n",
    "\n",
    "    # Create a multilevel indexed dataframe for easier read in the csv format (requested by users)\n",
    "    #resultant_df = pd.concat(df_dict.values(), axis=1, keys=df_dict.keys())\n",
    "    #resultant_df.to_csv(output_dir_and_name, sep=';')\n",
    "\n",
    "    #Try with excelwriter\n",
    "    with pd.ExcelWriter(output_dir_and_name) as writer:\n",
    "        for key, value in df_dict.items():\n",
    "            value.to_excel(writer,sheet_name=str(key))\n",
    "    #return resultant_df\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#    dfs2tocsv(sys.argv[1], sys.argv[2], sys.argv[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_ds = r'C:\\Project folder\\python_specialuppdrag\\MASV specialuppdrag\\06_Linnestaden_HPQ.dfs2'\n",
    "filepath_shp = r'C:\\Project folder\\python_specialuppdrag\\MASV specialuppdrag\\test_cells.shp'\n",
    "output_dir = r'C:\\Project folder\\python_specialuppdrag\\output_csvs\\heja.xls'\n",
    "#test = dfs2tocsv(filepath_ds,filepath_shp)\n",
    "ds = mi.read(filepath_ds)\n",
    "shape_df = gdp.read_file(filepath_shp)\n",
    "grid_size= get_grid_size(ds)\n",
    "test,coords,point_array= get_values_for_linestring(grid_size, ds, shape_df['geometry'][0])\n",
    "#dfs2tocsv(filepath_ds,filepath_shp,output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = r'C:\\Project folder\\python_specialuppdrag\\MASV specialuppdrag\\flux_dynamisk.dfs2'\n",
    "ds = mi.read(ds_path)\n",
    "test = pd.DataFrame()\n",
    "for coord in coords:\n",
    "    point_array = ds.sel(x=coord[0], y=coord[1]).to_dataframe()\n",
    "    test = pd.concat([test,point_array],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('from_maxflux.csv',sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\masv\\AppData\\Local\\Temp\\ipykernel_16000\\1494209363.py:5: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  df.to_file(r'C:\\Project folder\\python_specialuppdrag\\MASV specialuppdrag\\endast_tvo_comp.shp',driver = 'ESRI Shapefile')\n"
     ]
    }
   ],
   "source": [
    "to_shapefile = pd.DataFrame(data = {'coordinate_points':coords_list})\n",
    "from shapely.geometry import Point\n",
    "to_shapefile['coordinate_points'] = to_shapefile['coordinate_points'].apply(Point)\n",
    "df = gdp.GeoDataFrame(to_shapefile,geometry='coordinate_points')\n",
    "df.to_file(r'C:\\Project folder\\python_specialuppdrag\\MASV specialuppdrag\\endast_tvo_comp.shp',driver = 'ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Discharge + [meter^3/s]</th>\n",
       "      <th>Discharge - [meter^3/s]</th>\n",
       "      <th>Discharge [meter^3/s]</th>\n",
       "      <th>Cum. disc. + [meter^3]</th>\n",
       "      <th>Cum. disc. - [meter^3]</th>\n",
       "      <th>Cum. disc. [meter^3/s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-26 17:45:00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-26 17:50:00</td>\n",
       "      <td>1.414771e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.414771e-09</td>\n",
       "      <td>1.414771e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.414771e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-26 17:55:00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.037214</td>\n",
       "      <td>-3.721410e-02</td>\n",
       "      <td>1.414771e-09</td>\n",
       "      <td>-0.037214</td>\n",
       "      <td>-3.721410e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-26 18:00:00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.121917</td>\n",
       "      <td>-1.219171e-01</td>\n",
       "      <td>1.414771e-09</td>\n",
       "      <td>-0.159131</td>\n",
       "      <td>-1.591312e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-07-26 18:05:00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.347283</td>\n",
       "      <td>-3.472832e-01</td>\n",
       "      <td>1.414771e-09</td>\n",
       "      <td>-0.506414</td>\n",
       "      <td>-5.064144e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2014-07-27 05:40:00</td>\n",
       "      <td>2.126962e-21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.126962e-21</td>\n",
       "      <td>1.479084e-03</td>\n",
       "      <td>-14.748500</td>\n",
       "      <td>-1.474702e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2014-07-27 05:45:00</td>\n",
       "      <td>2.126962e-21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.126962e-21</td>\n",
       "      <td>1.479084e-03</td>\n",
       "      <td>-14.748500</td>\n",
       "      <td>-1.474702e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2014-07-27 05:50:00</td>\n",
       "      <td>2.126962e-21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.126962e-21</td>\n",
       "      <td>1.479084e-03</td>\n",
       "      <td>-14.748500</td>\n",
       "      <td>-1.474702e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2014-07-27 05:55:00</td>\n",
       "      <td>8.071340e-21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.071340e-21</td>\n",
       "      <td>1.479084e-03</td>\n",
       "      <td>-14.748500</td>\n",
       "      <td>-1.474702e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2014-07-27 06:00:00</td>\n",
       "      <td>2.126962e-21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.126962e-21</td>\n",
       "      <td>1.479084e-03</td>\n",
       "      <td>-14.748500</td>\n",
       "      <td>-1.474702e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   time  Discharge + [meter^3/s]  Discharge - [meter^3/s]  \\\n",
       "0   2014-07-26 17:45:00             0.000000e+00                 0.000000   \n",
       "1   2014-07-26 17:50:00             1.414771e-09                 0.000000   \n",
       "2   2014-07-26 17:55:00             0.000000e+00                -0.037214   \n",
       "3   2014-07-26 18:00:00             0.000000e+00                -0.121917   \n",
       "4   2014-07-26 18:05:00             0.000000e+00                -0.347283   \n",
       "..                  ...                      ...                      ...   \n",
       "143 2014-07-27 05:40:00             2.126962e-21                 0.000000   \n",
       "144 2014-07-27 05:45:00             2.126962e-21                 0.000000   \n",
       "145 2014-07-27 05:50:00             2.126962e-21                 0.000000   \n",
       "146 2014-07-27 05:55:00             8.071340e-21                 0.000000   \n",
       "147 2014-07-27 06:00:00             2.126962e-21                 0.000000   \n",
       "\n",
       "     Discharge [meter^3/s]  Cum. disc. + [meter^3]  Cum. disc. - [meter^3]  \\\n",
       "0             0.000000e+00            0.000000e+00                0.000000   \n",
       "1             1.414771e-09            1.414771e-09                0.000000   \n",
       "2            -3.721410e-02            1.414771e-09               -0.037214   \n",
       "3            -1.219171e-01            1.414771e-09               -0.159131   \n",
       "4            -3.472832e-01            1.414771e-09               -0.506414   \n",
       "..                     ...                     ...                     ...   \n",
       "143           2.126962e-21            1.479084e-03              -14.748500   \n",
       "144           2.126962e-21            1.479084e-03              -14.748500   \n",
       "145           2.126962e-21            1.479084e-03              -14.748500   \n",
       "146           8.071340e-21            1.479084e-03              -14.748500   \n",
       "147           2.126962e-21            1.479084e-03              -14.748500   \n",
       "\n",
       "     Cum. disc. [meter^3/s]  \n",
       "0              0.000000e+00  \n",
       "1              1.414771e-09  \n",
       "2             -3.721410e-02  \n",
       "3             -1.591312e-01  \n",
       "4             -5.064144e-01  \n",
       "..                      ...  \n",
       "143           -1.474702e+01  \n",
       "144           -1.474702e+01  \n",
       "145           -1.474702e+01  \n",
       "146           -1.474702e+01  \n",
       "147           -1.474702e+01  \n",
       "\n",
       "[148 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m shape_df \u001b[39m=\u001b[39m gdp\u001b[39m.\u001b[39mread_file(filepath_shp)\n\u001b[1;32m----> 2\u001b[0m shape_df\u001b[39m.\u001b[39;49mgeometry[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mcoords[\u001b[39m4\u001b[39;49m]\n",
      "File \u001b[1;32mc:\\Users\\masv\\AppData\\Local\\jupyterlabdesktopappserver\\lib\\site-packages\\shapely\\coords.py:85\u001b[0m, in \u001b[0;36mCoordinateSequence.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mint\u001b[39m):\n\u001b[0;32m     84\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cseq \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m key \u001b[39m+\u001b[39m m \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m key \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m m:\n\u001b[1;32m---> 85\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mindex out of range\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     87\u001b[0m         i \u001b[39m=\u001b[39m m \u001b[39m+\u001b[39m key\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range"
     ]
    }
   ],
   "source": [
    "shape_df = gdp.read_file(filepath_shp)\n",
    "shape_df.geometry[0].coords[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Resultant_flow'] = test.apply(lambda x: hypot(x['P flux <Flow Flux> (meter pow 3 per sec per meter)'],x['Q flux <Flow Flux> (meter pow 3 per sec per meter)']),axis=1)\n",
    "test['degrees'] = test.apply(lambda x:degrees(atan2(x['P flux <Flow Flux> (meter pow 3 per sec per meter)'],x['Q flux <Flow Flux> (meter pow 3 per sec per meter)'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P flux <Flow Flux> (meter pow 3 per sec per meter)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE TO AFTERNOON! if angle == (perpendicular+- 180): positive ,else negative (sort of) \n",
    "\n",
    "\n",
    "- No we have to extract at which SIDE the extraction point is from and then done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2=ds.sel(x = lineList[0][0],y=lineList[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147275.75"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.geometry.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_point_x = test2.geometry.x\n",
    "extracted_point_y = test2.geometry.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6395986.750004"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_point_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.38227428775020417"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atan2(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-158.7026459548892"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angle_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely.wkt\n",
    "import shapely.ops\n",
    "\n",
    "\n",
    "def reverse_geom(geom):\n",
    "    def _reverse(x, y, z=None):\n",
    "        if z:\n",
    "            return x[::-1], y[::-1], z[::-1]\n",
    "        return x[::-1], y[::-1]\n",
    "\n",
    "    return shapely.ops.transform(_reverse, geom)\n",
    "\n",
    "test3 = reverse_geom(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LINESTRING (147230.33088362962 6395969.038813498, 147277.16222729348 6395987.295100007)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3.wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LINESTRING (147277.16222729348 6395987.295100007, 147230.33088362962 6395969.038813498)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935633586779017"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-7.829035669739706/-8.36763"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
